model:
  vocab_size: 30000
  n_embd: 512
  n_head: 7
  n_layer: 6
  n_layer_decoder: 11
  max_position_embeddings: 512

data:
  dataset_name: "SouthernCrossAI/Project_Gutenberg_Australia"
  batch_size: 32
  shuffle: true
  num_workers: 4

optimizer:
  learning_rate: 0.0001
  weight_decay: 0.0
  optimizer_type: "Adam"

training:
  epochs: 10
  log_interval: 10
  save_model: true
  save_path: "models/babyjoey.pt"
  use_scheduler: false
